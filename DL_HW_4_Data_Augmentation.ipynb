{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL HW#4-Data Augmentation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvItR_d35uEc",
        "colab_type": "code",
        "outputId": "a96f1440-c7c3-405d-babc-8ab614a03b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyXCtsf96Ggj",
        "colab_type": "code",
        "outputId": "cc8e7903-1cb3-456d-d182-34da4cfd2760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TONKMuhGFYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# datagen.fit에 parameter로 넣기 위해서 이미지의 차원을 3차원으로 늘렸습니다.  =>  1 x 28 x 28\n",
        "train_images = train_images.reshape(train_images.shape[0], 1, train_images.shape[1], train_images.shape[2]).astype('float32') / 255\n",
        "test_images = test_images.reshape(test_images.shape[0], 1, test_images.shape[1], test_images.shape[2]).astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA2BO_Lb9YPu",
        "colab_type": "code",
        "outputId": "e249d43d-5882-45d7-d51e-12e309ab8cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkZMkEU8nAih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=90,       # 회전\n",
        "        height_shift_range=0.5,  # 상하 이동\n",
        "        zoom_range=0.5)          # 확대 범위"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ECwfMoVo1AV",
        "colab_type": "code",
        "outputId": "c296a1a2-d804-489f-9ec0-4d8a565210b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "datagen.fit(train_images)  # 이미지를 augmentation 해줍니다."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:940: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (60000, 1, 28, 28) (28 channels).\n",
            "  ' channels).')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGOVxuoxA4xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = np_utils.to_categorical(train_labels, 10)\n",
        "test_labels = np_utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4Rx5LMW2jr",
        "colab_type": "code",
        "outputId": "85c5e622-5fc4-4432-f327-be95a76b4e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model = Sequential()\n",
        "# 784의 1차원으로 augmentation 하는 법은 몰라서 3차원 이미지를 CNN으로 넣었습니다.\n",
        "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(1, 28, 28)))\n",
        "# 다음 층으로 전달할때는 1차원으로 변경하였습니다.\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 07:05:11.209043 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 07:05:11.253966 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 07:05:11.265288 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW0U2UlTCpmv",
        "colab_type": "code",
        "outputId": "70a5ed65-1e96-499f-fb5a-ed9f1ab85ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 07:05:11.344317 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 07:05:11.378561 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcCYM1-GF9GG",
        "colab_type": "code",
        "outputId": "b578f609-341d-4472-9440-002e14e4d812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "# flow를 통해 우선 batch 로 augmentation 된 이미지들을 가져옵니다.\n",
        "_batch = datagen.flow(train_images, train_labels, batch_size=512)\n",
        "for i in range(0, 9):\n",
        "  plt.subplot(330 + 1 + i)  # 331 ~ 339의 subplot\n",
        "  plt.imshow(_batch[i][0][0].reshape(28, 28))    # i번째 batch의 train_images 중 1번째  => 512 x 2 x 1 x 28 x 28 에서의 28 x 28\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:127: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (60000, 1, 28, 28) (28 channels).\n",
            "  str(self.x.shape[channels_axis]) + ' channels).')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkNveHT7fKqi",
        "colab_type": "code",
        "outputId": "797aa5aa-7920-484e-9fbb-2eb99d68a8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit_generator로 가져온 이미지들을 가지고 학습을 합니다.\n",
        "model.fit_generator(_batch, steps_per_epoch = 1, epochs = 300)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 07:05:16.828876 139881794787200 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0726 07:05:16.905617 139881794787200 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 7s 7s/step - loss: 2.3015 - acc: 0.1504\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1582 - acc: 0.2969\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0410 - acc: 0.3828\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9316 - acc: 0.4004\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8246 - acc: 0.4316\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7253 - acc: 0.4492\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5779 - acc: 0.4688\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4531 - acc: 0.5215\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.3772 - acc: 0.5195\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3399 - acc: 0.5645\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2755 - acc: 0.5840\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 1.2143 - acc: 0.6035\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 1.1595 - acc: 0.6055\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 1.0841 - acc: 0.6328\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 1.0927 - acc: 0.5996\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 1.0957 - acc: 0.6270\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 1.1573 - acc: 0.6133\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 1.0387 - acc: 0.6152\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.9113 - acc: 0.6621\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.9488 - acc: 0.6719\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.8975 - acc: 0.6426\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.9226 - acc: 0.6602\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.9429 - acc: 0.6797\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.9005 - acc: 0.7051\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.9245 - acc: 0.6699\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.8699 - acc: 0.7012\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.8098 - acc: 0.6992\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.9300 - acc: 0.6484\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.9651 - acc: 0.6504\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.8248 - acc: 0.6934\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.9549 - acc: 0.6719\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.8528 - acc: 0.6914\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.8001 - acc: 0.7051\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.8099 - acc: 0.7051\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.8448 - acc: 0.7148\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 1s 504ms/step - loss: 0.8715 - acc: 0.7031\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.8069 - acc: 0.7109\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.8361 - acc: 0.6777\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.8739 - acc: 0.6895\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.7973 - acc: 0.7109\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.8372 - acc: 0.6914\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.8136 - acc: 0.7051\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.8175 - acc: 0.6816\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.8153 - acc: 0.7051\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.8158 - acc: 0.6855\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.7470 - acc: 0.7188\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.7962 - acc: 0.6855\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.8162 - acc: 0.6973\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.8397 - acc: 0.6953\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.7558 - acc: 0.7324\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.7763 - acc: 0.7305\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.7711 - acc: 0.6973\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.8089 - acc: 0.6973\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7959 - acc: 0.7109\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.7201 - acc: 0.7500\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.7329 - acc: 0.7402\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.7589 - acc: 0.7285\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.7908 - acc: 0.7188\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.7141 - acc: 0.7480\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.7249 - acc: 0.7246\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 1s 507ms/step - loss: 0.7536 - acc: 0.7012\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7744 - acc: 0.7051\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.7179 - acc: 0.7441\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.7905 - acc: 0.6973\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.7606 - acc: 0.7246\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7620 - acc: 0.7305\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.7912 - acc: 0.6973\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.7787 - acc: 0.7031\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.7351 - acc: 0.7227\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.7546 - acc: 0.7227\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.8331 - acc: 0.6973\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.7557 - acc: 0.7070\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6869 - acc: 0.7695\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.7901 - acc: 0.7070\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.7548 - acc: 0.7324\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 0.7462 - acc: 0.7070\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.6734 - acc: 0.7383\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.7222 - acc: 0.7520\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.7580 - acc: 0.7266\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.7102 - acc: 0.7246\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6723 - acc: 0.7578\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.7687 - acc: 0.7480\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.6489 - acc: 0.7676\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.7077 - acc: 0.7480\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 1s 522ms/step - loss: 0.7461 - acc: 0.7363\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.7318 - acc: 0.7285\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6974 - acc: 0.7441\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.7006 - acc: 0.7461\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.7093 - acc: 0.7383\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.7688 - acc: 0.7266\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.7335 - acc: 0.7461\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6978 - acc: 0.7598\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.7920 - acc: 0.7129\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.8158 - acc: 0.6934\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.7123 - acc: 0.7402\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.7169 - acc: 0.7441\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6750 - acc: 0.7520\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.6930 - acc: 0.7617\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6509 - acc: 0.7812\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 1s 505ms/step - loss: 0.7478 - acc: 0.7480\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6290 - acc: 0.7559\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.7531 - acc: 0.7383\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.7555 - acc: 0.7285\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.7315 - acc: 0.7383\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.5793 - acc: 0.8125\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.7083 - acc: 0.7344\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.7191 - acc: 0.7656\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.7240 - acc: 0.7402\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6805 - acc: 0.7363\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.7779 - acc: 0.7266\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.7372 - acc: 0.7207\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 497ms/step - loss: 0.6568 - acc: 0.7715\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6319 - acc: 0.7695\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7777 - acc: 0.7148\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.7379 - acc: 0.7246\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7963 - acc: 0.7344\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6918 - acc: 0.7422\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.9832 - acc: 0.6875\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7227 - acc: 0.7305\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.7084 - acc: 0.7559\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6668 - acc: 0.7695\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.6838 - acc: 0.7461\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7494 - acc: 0.7266\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.6933 - acc: 0.7441\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6778 - acc: 0.7539\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.7258 - acc: 0.7441\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6632 - acc: 0.7656\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.6715 - acc: 0.7520\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.7294 - acc: 0.7285\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.7721 - acc: 0.7383\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7211 - acc: 0.7402\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6565 - acc: 0.7559\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6738 - acc: 0.7422\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6787 - acc: 0.7402\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6800 - acc: 0.7520\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.7269 - acc: 0.7441\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6355 - acc: 0.7637\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.7284 - acc: 0.7461\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6471 - acc: 0.7812\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.6499 - acc: 0.7539\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6597 - acc: 0.7676\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6454 - acc: 0.7500\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6192 - acc: 0.7676\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.7056 - acc: 0.7559\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6222 - acc: 0.7773\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.7371 - acc: 0.7090\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7236 - acc: 0.7363\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.6553 - acc: 0.7656\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6522 - acc: 0.7617\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.7650 - acc: 0.7324\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.6190 - acc: 0.7715\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.6820 - acc: 0.7402\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.6733 - acc: 0.7734\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.5926 - acc: 0.7559\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6614 - acc: 0.7695\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6351 - acc: 0.7832\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 495ms/step - loss: 0.6817 - acc: 0.7324\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6585 - acc: 0.7715\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.6669 - acc: 0.7500\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6778 - acc: 0.7598\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6622 - acc: 0.7441\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6783 - acc: 0.7422\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6669 - acc: 0.7402\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6328 - acc: 0.7598\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6407 - acc: 0.7773\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.7140 - acc: 0.7578\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6472 - acc: 0.7754\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6816 - acc: 0.7617\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.6718 - acc: 0.7402\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6648 - acc: 0.7578\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.7179 - acc: 0.7148\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6700 - acc: 0.7461\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 473ms/step - loss: 0.6115 - acc: 0.8066\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6213 - acc: 0.7656\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.6964 - acc: 0.7500\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6882 - acc: 0.7559\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6549 - acc: 0.7617\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7057 - acc: 0.7480\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6958 - acc: 0.7422\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6261 - acc: 0.7695\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6629 - acc: 0.7656\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.7038 - acc: 0.7480\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6671 - acc: 0.7461\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6495 - acc: 0.7520\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6045 - acc: 0.7793\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.7104 - acc: 0.7402\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6788 - acc: 0.7324\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.6876 - acc: 0.7461\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6513 - acc: 0.7500\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.6751 - acc: 0.7656\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6987 - acc: 0.7383\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.7058 - acc: 0.7266\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6256 - acc: 0.7734\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6267 - acc: 0.7617\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6847 - acc: 0.7246\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.7263 - acc: 0.7422\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6198 - acc: 0.7969\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.5484 - acc: 0.8203\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6782 - acc: 0.7598\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6841 - acc: 0.7285\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.7512 - acc: 0.7461\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6484 - acc: 0.7578\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6259 - acc: 0.7441\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6488 - acc: 0.7461\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6959 - acc: 0.7266\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.7069 - acc: 0.7480\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6196 - acc: 0.7598\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.7208 - acc: 0.7266\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.7155 - acc: 0.7402\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.7607 - acc: 0.7520\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.5911 - acc: 0.7852\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.5994 - acc: 0.7852\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 471ms/step - loss: 0.6181 - acc: 0.7793\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6675 - acc: 0.7734\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.6725 - acc: 0.7559\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.5924 - acc: 0.7715\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.6308 - acc: 0.7637\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.7028 - acc: 0.7344\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.5874 - acc: 0.8086\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5857 - acc: 0.7754\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6301 - acc: 0.7832\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.5958 - acc: 0.7910\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.5949 - acc: 0.7969\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.6294 - acc: 0.7852\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6269 - acc: 0.7617\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6104 - acc: 0.7852\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.6890 - acc: 0.7656\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6187 - acc: 0.7754\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.7056 - acc: 0.7441\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6400 - acc: 0.7676\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6904 - acc: 0.7539\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6787 - acc: 0.7461\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6011 - acc: 0.7949\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6433 - acc: 0.7812\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6908 - acc: 0.7578\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.5837 - acc: 0.7188\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6700 - acc: 0.7578\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6684 - acc: 0.7617\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6422 - acc: 0.7578\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6530 - acc: 0.7656\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6377 - acc: 0.7871\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6262 - acc: 0.7832\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.5760 - acc: 0.7949\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6392 - acc: 0.7676\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.6463 - acc: 0.7598\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6377 - acc: 0.7637\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6890 - acc: 0.7539\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6504 - acc: 0.7598\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.5994 - acc: 0.7559\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.5912 - acc: 0.7832\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6282 - acc: 0.7852\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.7053 - acc: 0.7441\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6526 - acc: 0.7598\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6301 - acc: 0.7617\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6293 - acc: 0.7578\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6351 - acc: 0.7812\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.6820 - acc: 0.7598\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6376 - acc: 0.7520\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6217 - acc: 0.7930\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6224 - acc: 0.7695\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6188 - acc: 0.7715\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6482 - acc: 0.7852\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.5430 - acc: 0.8164\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6307 - acc: 0.7715\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.5667 - acc: 0.7793\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6029 - acc: 0.7988\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6714 - acc: 0.7402\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.5701 - acc: 0.7832\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.6321 - acc: 0.7734\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6575 - acc: 0.7520\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6586 - acc: 0.7422\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6355 - acc: 0.7812\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6077 - acc: 0.7715\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.6228 - acc: 0.7539\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6459 - acc: 0.7637\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.7152 - acc: 0.7617\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6225 - acc: 0.7812\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6130 - acc: 0.7793\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.5627 - acc: 0.7852\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.6556 - acc: 0.7637\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.5449 - acc: 0.8066\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5712 - acc: 0.7988\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.6846 - acc: 0.7520\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.6214 - acc: 0.7812\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.5967 - acc: 0.7910\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.5949 - acc: 0.7891\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5766 - acc: 0.7793\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6176 - acc: 0.7832\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6481 - acc: 0.7617\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6004 - acc: 0.7910\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.5845 - acc: 0.8086\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6416 - acc: 0.7559\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6292 - acc: 0.7676\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.6000 - acc: 0.7832\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 479ms/step - loss: 0.5453 - acc: 0.8105\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.6041 - acc: 0.7793\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 477ms/step - loss: 0.5627 - acc: 0.7969\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.6657 - acc: 0.7715\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.6572 - acc: 0.7520\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.5875 - acc: 0.7676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38793d94a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAj7xxkJgRTu",
        "colab_type": "code",
        "outputId": "96b104fb-59f6-47b0-beec-05493ab1efc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Accuracy : %.4f\" % (model.evaluate(test_images, test_labels)[1]))\n",
        "# 만약 모든 모델의 Test set에 대해 augmentation을 적용했다면 이 모델이 더 좋은 성능을 보였을 것 같습니다."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 109us/step\n",
            "Accuracy : 0.8228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}