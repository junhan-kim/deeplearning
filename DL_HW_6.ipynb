{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "YvItR_d35uEc",
    "outputId": "334a85f3-18d2-469b-b34e-4dd5f276ed11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, LeakyReLU, Activation, BatchNormalization, ZeroPadding2D, Add, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import Input\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "AyXCtsf96Ggj",
    "outputId": "3b90d272-0c25-456b-a9e3-f949c3efcb4c"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "ujmwQLoALRgg",
    "outputId": "3168d2db-c1cc-4ffb-8ff8-4e17382a6a7b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7TONKMuhGFYO",
    "outputId": "e3068367-d207-48ba-b6ba-735c41a5e97e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1).astype('float32') / 255\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1).astype('float32') / 255\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "fGOVxuoxA4xd",
    "outputId": "947d86fc-c5c1-4f61-fe1f-3b68b49505e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np_utils.to_categorical(train_labels, 10)\n",
    "test_labels = np_utils.to_categorical(test_labels, 10)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3POxHbTcEP4P"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "use_scale = 0.05  # 메모리가 부족하여, 트레이닝 셋을 줄였습니다.\n",
    "i = 0\n",
    "resized_train_images = []\n",
    "resized_test_images = []\n",
    "while i < len(train_images) * use_scale:\n",
    "  resized_image = cv2.resize(train_images[i], (224, 224), interpolation = cv2.INTER_AREA)  # 28x28 to 224 x 224\n",
    "  resized_train_images.append(resized_image)\n",
    "  resized_image = cv2.resize(test_images[i], (224, 224), interpolation = cv2.INTER_AREA)\n",
    "  resized_test_images.append(resized_image)\n",
    "  i += 1\n",
    "\n",
    "del(train_images)\n",
    "del(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "1msD-Xs8JpkJ",
    "outputId": "272f1543-ca15-43f0-aa69-f5bea8534799"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np.array(resized_train_images[0])\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a98auN84fphL"
   },
   "outputs": [],
   "source": [
    "np_resized_train_images = np.asarray(resized_train_images, dtype=np.float32)  # array to numpy\n",
    "np_resized_test_images = np.asarray(resized_test_images, dtype=np.float32)\n",
    "del(resized_train_images)\n",
    "del(resized_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-hV7TOVgn2x"
   },
   "outputs": [],
   "source": [
    "# 28 x 28 to 28 x 28 x 1\n",
    "np_resized_train_images = np_resized_train_images.reshape(np_resized_train_images.shape[0], np_resized_train_images.shape[1], np_resized_train_images.shape[2], 1)\n",
    "np_resized_test_images = np_resized_test_images.reshape(np_resized_test_images.shape[0], np_resized_test_images.shape[1], np_resized_test_images.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "xQSnnfVvhygs",
    "outputId": "01d5074f-1513-4d95-a4ec-965db074ffc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 224, 224, 1)\n",
      "(3000, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np_resized_train_images.shape)\n",
    "print(np_resized_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7DNxV82vWlL"
   },
   "outputs": [],
   "source": [
    "# 28 x 28 x 1 to 28 x 28 x 3\n",
    "# 단순히 1개의 채널에 있던 값을 복사하여 3개의 채널로 만들었습니다.. \n",
    "# 별다른 복원 알고리즘이 없어서 그런지,  흑백이미지가 되었습니다\n",
    "np_stacked_resized_train_images = np.stack((np_resized_train_images,)*3, axis=-1)\n",
    "np_stacked_resized_train_images = np.squeeze(np_stacked_resized_train_images)\n",
    "np_stacked_resized_test_images = np.stack((np_resized_test_images,)*3, axis=-1)\n",
    "np_stacked_resized_test_images = np.squeeze(np_stacked_resized_test_images)\n",
    "del(np_resized_train_images)\n",
    "del(np_resized_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "colab_type": "code",
    "id": "Dc0KwFfvzeLa",
    "outputId": "f367ccc6-ba16-4c34-9689-8b84bf9e86ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(np_stacked_resized_train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "kxr9X_b7MZH0",
    "outputId": "5272aabd-4fa0-4fb7-9b7b-8acce3e02a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 224, 224, 3)\n",
      "(3000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np_stacked_resized_train_images.shape)\n",
    "print(np_stacked_resized_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "_fpd7yxGpOAR",
    "outputId": "0a57fc3f-ab16-41a6-c41e-88bccb583f9a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np_stacked_resized_train_images[0]\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = np_stacked_resized_test_images[0]\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "sabnz_c5IqJh",
    "outputId": "0d1ca2b8-298e-4ae3-9ea4-c60febd4a95c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 17:15:51.393556  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 시작 (resnet 50)\n",
    "\n",
    "from keras import Input\n",
    "input_tensor = Input(shape=(224, 224, 3), dtype='float32', name='input')  # input : 224 x 224 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Fu0IC5pe7o8B",
    "outputId": "d6d22d09-7ba2-4e96-9a54-7c30aab7dde1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 17:15:51.438530  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0818 17:15:51.445528  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0818 17:15:51.481506  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0818 17:15:51.482505  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0818 17:15:53.039614  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conv 1\n",
    "\n",
    "x = ZeroPadding2D(padding=(3, 3))(input_tensor)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2))(x)   # Conv 7x7, 64, /2\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1,1))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "Wkg6z5DT97zj",
    "outputId": "67fc88a6-c07d-4db9-bb5c-1be2fa845c79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 17:15:53.148553  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conv 2\n",
    "\n",
    "x = MaxPooling2D((3, 3), 2)(x)  # pool /2\n",
    "\n",
    "shortcut = x   # x\n",
    "\n",
    "for i in range(3):\n",
    "    if (i == 0):  # 첫번째 루프에서는 shortcut의 필터크기가 x와 일치하지 않으므로 일치하게 만들어줍니다.\n",
    "        x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)  # filter 는 2배씩 증가\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)   # kernel size가 1 -> 3 -> 1로 변하는 bottle neck 구간\n",
    "        x = BatchNormalization()(x)  # Conv 3x3, 64\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)  \n",
    "        shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "        x = BatchNormalization()(x)    #  F(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "        x = Add()([x, shortcut])  #  x + F(x), skip connection\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        shortcut = x  # 이전 루프 결과 저장\n",
    "\n",
    "    else:\n",
    "        x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)            \n",
    "\n",
    "        x = Add()([x, shortcut])   \n",
    "        x = Activation('relu')(x)  \n",
    "\n",
    "        shortcut = x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGWxsscNJjh8"
   },
   "outputs": [],
   "source": [
    "# Conv 3\n",
    "\n",
    "shortcut = x    \n",
    "    \n",
    "for i in range(4):     \n",
    "    if(i == 0):          \n",
    "        # pooling을 하였던 Conv2를 제외하고는 각 Conv 레이어의 첫 부분은 stride를 2로 함\n",
    "        x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)                                                                       \n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)        \n",
    "\n",
    "        x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)    # Conv 3x3, 128\n",
    "        x = Activation('relu')(x)  \n",
    "\n",
    "        x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "        x = BatchNormalization()(x)\n",
    "        shortcut = BatchNormalization()(shortcut)            \n",
    "\n",
    "        x = Add()([x, shortcut])    \n",
    "        x = Activation('relu')(x)    \n",
    "\n",
    "        shortcut = x              \n",
    "\n",
    "    else:\n",
    "        x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)            \n",
    "\n",
    "        x = Add()([x, shortcut])     \n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        shortcut = x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-WSAD4huJj69"
   },
   "outputs": [],
   "source": [
    "# Conv 4\n",
    "\n",
    "shortcut = x        \n",
    "\n",
    "for i in range(6):     \n",
    "    if(i == 0):            \n",
    "        x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)        \n",
    "\n",
    "        x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)   # Conv 3x3, 256\n",
    "        x = Activation('relu')(x)  \n",
    "\n",
    "        x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "        x = BatchNormalization()(x)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "        x = Add()([x, shortcut]) \n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        shortcut = x               \n",
    "\n",
    "    else:\n",
    "        x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)            \n",
    "\n",
    "        x = Add()([x, shortcut])    \n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        shortcut = x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oySRrH2qGdWd"
   },
   "outputs": [],
   "source": [
    "# Conv 5\n",
    "\n",
    "shortcut = x    \n",
    "\n",
    "for i in range(3):     \n",
    "    if(i == 0):            \n",
    "        x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)        \n",
    "\n",
    "        x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)   # Conv 3x3, 512\n",
    "        x = Activation('relu')(x)  \n",
    "\n",
    "        x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "        x = BatchNormalization()(x)\n",
    "        shortcut = BatchNormalization()(shortcut)            \n",
    "\n",
    "        x = Add()([x, shortcut])  \n",
    "        x = Activation('relu')(x)      \n",
    "\n",
    "        shortcut = x               \n",
    "\n",
    "    else:\n",
    "        x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)           \n",
    "\n",
    "        x = Add()([x, shortcut]) \n",
    "        x = Activation('relu')(x)       \n",
    "\n",
    "        shortcut = x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YIsNFweTJtDZ",
    "outputId": "a9f5a4a7-6271-4076-ca42-dfb40daa9507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9472        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 1024) 4096        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_31[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_37[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_40[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 1024) 4096        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 2048)   8192        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 512)    2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 2048)   8192        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_50[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 512)    2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 2048)   8192        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_53[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = GlobalAveragePooling2D()(x)   # 1차원으로 풀링(플래트닝)\n",
    "output_tensor = Dense(10, activation='softmax')(x)  # output\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)  # input과 output을 가지고 model 생성\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "id": "XU47eog0LyIT",
    "outputId": "2a656d4d-f249-4ac3-b541-a4d8310bd1b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 17:16:02.028090  7320 deprecation_wrapper.py:119] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resnet50.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kc0XzLLQPGpr"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels[0:3000, :]   # train_image 갯수에 맞게 label 갯수 조정\n",
    "test_labels = test_labels[0:3000, :]   # train_image 갯수에 맞게 label 갯수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "WiIk2YTlPWGu",
    "outputId": "5eab918d-3a2c-4d15-b7a7-d2edfd1ddfc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 10)\n",
      "(3000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "colab_type": "code",
    "id": "VvxjaTJAL5Z9",
    "outputId": "a1da4236-3716-4aa0-acd0-afb41d9583ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 17:16:02.266952  7320 deprecation.py:323] From d:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3000/3000 [==============================] - 220s 73ms/step - loss: 1.6990 - acc: 0.4523\n",
      "Epoch 2/20\n",
      "3000/3000 [==============================] - 197s 66ms/step - loss: 0.9152 - acc: 0.6713\n",
      "Epoch 3/20\n",
      "3000/3000 [==============================] - 200s 67ms/step - loss: 0.8190 - acc: 0.7147\n",
      "Epoch 4/20\n",
      "3000/3000 [==============================] - 201s 67ms/step - loss: 0.7100 - acc: 0.7530\n",
      "Epoch 5/20\n",
      "3000/3000 [==============================] - 195s 65ms/step - loss: 0.6263 - acc: 0.7713\n",
      "Epoch 6/20\n",
      "3000/3000 [==============================] - 191s 64ms/step - loss: 0.5625 - acc: 0.7930\n",
      "Epoch 7/20\n",
      "3000/3000 [==============================] - 194s 65ms/step - loss: 0.5230 - acc: 0.8163\n",
      "Epoch 8/20\n",
      "3000/3000 [==============================] - 193s 64ms/step - loss: 0.4959 - acc: 0.8160\n",
      "Epoch 9/20\n",
      "3000/3000 [==============================] - 194s 65ms/step - loss: 0.4698 - acc: 0.8323\n",
      "Epoch 10/20\n",
      "3000/3000 [==============================] - 198s 66ms/step - loss: 0.4425 - acc: 0.8400\n",
      "Epoch 11/20\n",
      "3000/3000 [==============================] - 182s 61ms/step - loss: 0.3946 - acc: 0.8613\n",
      "Epoch 12/20\n",
      "3000/3000 [==============================] - 195s 65ms/step - loss: 0.4052 - acc: 0.8503\n",
      "Epoch 13/20\n",
      "3000/3000 [==============================] - 193s 64ms/step - loss: 0.3589 - acc: 0.8667\n",
      "Epoch 14/20\n",
      "3000/3000 [==============================] - 188s 63ms/step - loss: 0.3423 - acc: 0.8663\n",
      "Epoch 15/20\n",
      "3000/3000 [==============================] - 195s 65ms/step - loss: 0.2964 - acc: 0.8907\n",
      "Epoch 16/20\n",
      "3000/3000 [==============================] - 192s 64ms/step - loss: 0.2980 - acc: 0.8853\n",
      "Epoch 17/20\n",
      "3000/3000 [==============================] - 194s 65ms/step - loss: 0.2552 - acc: 0.9043\n",
      "Epoch 18/20\n",
      "3000/3000 [==============================] - 188s 63ms/step - loss: 0.2216 - acc: 0.9170\n",
      "Epoch 19/20\n",
      "3000/3000 [==============================] - 194s 65ms/step - loss: 0.2224 - acc: 0.9120\n",
      "Epoch 20/20\n",
      "3000/3000 [==============================] - 185s 62ms/step - loss: 0.1737 - acc: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2edc70650b8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리 한계를 고려하여 batch_size는 4,  epoch은 20으로 함 \n",
    "resnet50.fit(np_stacked_resized_train_images, train_labels, epochs=20, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lp2fZMsCL6vy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 33s 11ms/step\n",
      "Accuracy : 0.8513\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy : %.4f\" % (resnet50.evaluate(np_stacked_resized_test_images, test_labels)[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DL HW#6",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
