{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL HW#5",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvItR_d35uEc",
        "colab_type": "code",
        "outputId": "91117ac7-6cca-425f-c818-032110311963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, LeakyReLU, Activation, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyXCtsf96Ggj",
        "colab_type": "code",
        "outputId": "5f90b9eb-115e-456c-d670-1516ba4ea694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TONKMuhGFYO",
        "colab_type": "code",
        "outputId": "1cb2805b-f737-4329-966b-a3920096bb60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1).astype('float32') / 255\n",
        "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1], test_images.shape[2], 1).astype('float32') / 255\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGOVxuoxA4xd",
        "colab_type": "code",
        "outputId": "8a09c8c4-523a-46bf-e660-cda982472a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "train_labels = np_utils.to_categorical(train_labels, 10)\n",
        "test_labels = np_utils.to_categorical(test_labels, 10)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvUdHQ3Mdbcs",
        "colab_type": "code",
        "outputId": "224dfd14-8109-4aec-92c6-7350575e3b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "# kernel_size  2 by 2       Acc : 91.49   \n",
        "#              3 by 3       Acc : 92.14\n",
        "# leaky_ReLU   use        \n",
        "#               (a = 0.1)   Acc : 92.14  \n",
        "#               (a = 0.01)  Acc : 91.84\n",
        "#              not use      Acc : 91.79\n",
        "# use BN       use          Acc : \n",
        "#              not use      Acc : 93.37\n",
        "\n",
        "# Model 1\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', input_shape = (28, 28, 1)))\n",
        "model1.add(LeakyReLU(alpha=0.1))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same'))\n",
        "model1.add(LeakyReLU(alpha=0.1))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same'))\n",
        "model1.add(LeakyReLU(alpha=0.1))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same'))\n",
        "model1.add(LeakyReLU(alpha=0.1))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same'))\n",
        "model1.add(LeakyReLU(alpha=0.1))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model1.add(Dropout(0.25))\n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(512))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(BatchNormalization(axis=-1))\n",
        "model1.add(Dropout(0.5))\n",
        "\n",
        "model1.add(Dense(10))\n",
        "model1.add(Activation('softmax'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 08:03:58.308495 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0809 08:03:58.352232 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0809 08:03:58.359042 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0809 08:03:58.396958 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0809 08:03:58.397863 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0809 08:04:01.423356 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0809 08:04:01.565787 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0809 08:04:01.574655 140393059452800 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6wQUSCXlID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 2\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (2, 2), padding = 'same', input_shape = (28, 28, 1)))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(Conv2D(filters = 32, kernel_size = (2, 2), padding = 'same'))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same'))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(Conv2D(filters = 64, kernel_size = (2, 2), padding = 'same'))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(filters = 128, kernel_size = (2, 2), padding = 'same'))\n",
        "model2.add(LeakyReLU(alpha=0.1))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(BatchNormalization(axis=-1))\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(10))\n",
        "model2.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKnA2I1hxJeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test size   0.1    Acc : 91.72\n",
        "#             0.2    Acc : 92.19\n",
        "#             0.3    Acc : 91.38\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Ae5Z7cY6G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "models.append(model1)\n",
        "models.append(model2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW0U2UlTCpmv",
        "colab_type": "code",
        "outputId": "12ca96fd-ac15-40ca-8ffd-1d1b6eab77eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "for n_model in models:\n",
        "  n_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "# default :     Acc : 91.88\n",
        "# lr = 0.01     Acc : 87.99\n",
        "# lr = 0.001    Acc : 92.17\n",
        "# lr = 0.0001   Acc : 91.52"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 08:04:02.811054 140393059452800 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDTeEWio2Puu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# patience  2    Acc : 92.14\n",
        "#           5    Acc : 92.17\n",
        "#           10   Acc : 92.39\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10), ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkNveHT7fKqi",
        "colab_type": "code",
        "outputId": "76da4034-953b-4e78-865b-75a7bfdb00bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# epoch    20    Acc : 92.14\n",
        "#          30    Acc : 92.02\n",
        "#          40    Acc : 92.29\n",
        "#          50    Acc : 92.37\n",
        "#          70    Acc : 92.14\n",
        "for n_model in models:\n",
        "  n_model.fit(train_images, train_labels, epochs=100, batch_size=128, validation_data=(val_images, val_labels), callbacks = callbacks)  # 마지막엔 100정도"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 08:04:02.962446 140393059452800 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 13s 265us/step - loss: 0.6227 - acc: 0.7868 - val_loss: 0.3500 - val_acc: 0.8730\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.3679 - acc: 0.8653 - val_loss: 0.3096 - val_acc: 0.8899\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.3149 - acc: 0.8841 - val_loss: 0.2706 - val_acc: 0.9018\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2800 - acc: 0.8977 - val_loss: 0.2621 - val_acc: 0.9070\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2629 - acc: 0.9039 - val_loss: 0.2374 - val_acc: 0.9112\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2498 - acc: 0.9081 - val_loss: 0.3043 - val_acc: 0.8922\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2351 - acc: 0.9127 - val_loss: 0.2243 - val_acc: 0.9198\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2239 - acc: 0.9179 - val_loss: 0.2192 - val_acc: 0.9205\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.2165 - acc: 0.9206 - val_loss: 0.2264 - val_acc: 0.9209\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.2042 - acc: 0.9243 - val_loss: 0.2013 - val_acc: 0.9287\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1979 - acc: 0.9275 - val_loss: 0.2020 - val_acc: 0.9253\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.1926 - acc: 0.9270 - val_loss: 0.2115 - val_acc: 0.9221\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1872 - acc: 0.9316 - val_loss: 0.2220 - val_acc: 0.9202\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 8s 160us/step - loss: 0.1816 - acc: 0.9321 - val_loss: 0.1876 - val_acc: 0.9292\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1758 - acc: 0.9341 - val_loss: 0.2239 - val_acc: 0.9197\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.1709 - acc: 0.9357 - val_loss: 0.1835 - val_acc: 0.9333\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.1640 - acc: 0.9392 - val_loss: 0.1748 - val_acc: 0.9361\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1582 - acc: 0.9415 - val_loss: 0.1871 - val_acc: 0.9344\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1523 - acc: 0.9436 - val_loss: 0.2108 - val_acc: 0.9292\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 8s 158us/step - loss: 0.1496 - acc: 0.9443 - val_loss: 0.1978 - val_acc: 0.9299\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1454 - acc: 0.9454 - val_loss: 0.1978 - val_acc: 0.9342\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1409 - acc: 0.9466 - val_loss: 0.2041 - val_acc: 0.9311\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1399 - acc: 0.9485 - val_loss: 0.2584 - val_acc: 0.9167\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1318 - acc: 0.9511 - val_loss: 0.1839 - val_acc: 0.9369\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1304 - acc: 0.9514 - val_loss: 0.1872 - val_acc: 0.9369\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1278 - acc: 0.9519 - val_loss: 0.1775 - val_acc: 0.9369\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 8s 159us/step - loss: 0.1247 - acc: 0.9538 - val_loss: 0.1833 - val_acc: 0.9387\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 9s 177us/step - loss: 0.6537 - acc: 0.7749 - val_loss: 0.3816 - val_acc: 0.8648\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.3978 - acc: 0.8574 - val_loss: 0.3228 - val_acc: 0.8820\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.3336 - acc: 0.8792 - val_loss: 0.2698 - val_acc: 0.9015\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.3071 - acc: 0.8883 - val_loss: 0.2796 - val_acc: 0.8977\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2853 - acc: 0.8958 - val_loss: 0.2472 - val_acc: 0.9107\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2707 - acc: 0.9009 - val_loss: 0.2321 - val_acc: 0.9150\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2585 - acc: 0.9057 - val_loss: 0.2333 - val_acc: 0.9141\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.2461 - acc: 0.9102 - val_loss: 0.2276 - val_acc: 0.9163\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.2415 - acc: 0.9119 - val_loss: 0.2364 - val_acc: 0.9145\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.2310 - acc: 0.9153 - val_loss: 0.2229 - val_acc: 0.9223\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 7s 149us/step - loss: 0.2237 - acc: 0.9180 - val_loss: 0.2314 - val_acc: 0.9175\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.2170 - acc: 0.9192 - val_loss: 0.2334 - val_acc: 0.9150\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2115 - acc: 0.9228 - val_loss: 0.2147 - val_acc: 0.9257\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2039 - acc: 0.9261 - val_loss: 0.2275 - val_acc: 0.9212\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.2016 - acc: 0.9247 - val_loss: 0.2028 - val_acc: 0.9273\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1977 - acc: 0.9267 - val_loss: 0.1934 - val_acc: 0.9322\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1944 - acc: 0.9283 - val_loss: 0.2253 - val_acc: 0.9203\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.1879 - acc: 0.9305 - val_loss: 0.1976 - val_acc: 0.9318\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1856 - acc: 0.9317 - val_loss: 0.1978 - val_acc: 0.9294\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1812 - acc: 0.9324 - val_loss: 0.2011 - val_acc: 0.9292\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1763 - acc: 0.9346 - val_loss: 0.1835 - val_acc: 0.9327\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1721 - acc: 0.9360 - val_loss: 0.1935 - val_acc: 0.9338\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.1687 - acc: 0.9369 - val_loss: 0.1929 - val_acc: 0.9332\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1700 - acc: 0.9367 - val_loss: 0.2085 - val_acc: 0.9244\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.1654 - acc: 0.9386 - val_loss: 0.1923 - val_acc: 0.9318\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1608 - acc: 0.9408 - val_loss: 0.2018 - val_acc: 0.9319\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1611 - acc: 0.9397 - val_loss: 0.2030 - val_acc: 0.9307\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1536 - acc: 0.9426 - val_loss: 0.1892 - val_acc: 0.9347\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1508 - acc: 0.9434 - val_loss: 0.1820 - val_acc: 0.9372\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1461 - acc: 0.9444 - val_loss: 0.1860 - val_acc: 0.9387\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 7s 148us/step - loss: 0.1427 - acc: 0.9469 - val_loss: 0.1947 - val_acc: 0.9348\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1471 - acc: 0.9452 - val_loss: 0.1905 - val_acc: 0.9348\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1447 - acc: 0.9465 - val_loss: 0.1856 - val_acc: 0.9390\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1383 - acc: 0.9482 - val_loss: 0.1891 - val_acc: 0.9348\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1375 - acc: 0.9482 - val_loss: 0.1896 - val_acc: 0.9369\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1365 - acc: 0.9483 - val_loss: 0.1779 - val_acc: 0.9419\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1348 - acc: 0.9496 - val_loss: 0.1870 - val_acc: 0.9369\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1331 - acc: 0.9512 - val_loss: 0.1974 - val_acc: 0.9353\n",
            "Epoch 39/100\n",
            "48000/48000 [==============================] - 7s 146us/step - loss: 0.1292 - acc: 0.9511 - val_loss: 0.1885 - val_acc: 0.9370\n",
            "Epoch 40/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1287 - acc: 0.9513 - val_loss: 0.1996 - val_acc: 0.9369\n",
            "Epoch 41/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1248 - acc: 0.9525 - val_loss: 0.1854 - val_acc: 0.9398\n",
            "Epoch 42/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1258 - acc: 0.9516 - val_loss: 0.1817 - val_acc: 0.9399\n",
            "Epoch 43/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1214 - acc: 0.9549 - val_loss: 0.1924 - val_acc: 0.9410\n",
            "Epoch 44/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1224 - acc: 0.9537 - val_loss: 0.1973 - val_acc: 0.9381\n",
            "Epoch 45/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1181 - acc: 0.9556 - val_loss: 0.1860 - val_acc: 0.9421\n",
            "Epoch 46/100\n",
            "48000/48000 [==============================] - 7s 147us/step - loss: 0.1161 - acc: 0.9567 - val_loss: 0.1867 - val_acc: 0.9394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAj7xxkJgRTu",
        "colab_type": "code",
        "outputId": "7e217c80-19c5-4444-e4fa-4d0d5231d7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "for n_model in models:\n",
        "  print(\"Accuracy : %.4f\" % (n_model.evaluate(test_images, test_labels)[1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Accuracy : 0.9345\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Accuracy : 0.9348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDe__0ZlZiL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "eca86e9b-1dfc-456c-8fb1-fe49ac612352"
      },
      "source": [
        "labels = []\n",
        "for n_model in models:\n",
        "    predicts = np.argmax(n_model.predict(test_images), axis=1)\n",
        "    labels.append(predicts)   # 각 model에서의 predicted label을 label에 넣습니다.\n",
        "print(labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([9, 2, 1, ..., 8, 1, 5]), array([9, 2, 1, ..., 8, 1, 5])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxRTXy9QZsmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "f6666ace-37eb-4054-dae1-54e8df823323"
      },
      "source": [
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "labels = np.array(labels)   \n",
        "print(labels)\n",
        "labels = np.transpose(labels, (1, 0))  # 각 column은 모델들이 특정 이미지에 대해 voting한 값들의 모임이 됩니다.\n",
        "print(labels)\n",
        "labels = scipy.stats.mode(labels, axis=1)[0]   # scipy.stats.mode => 세 모델이 내놓은 prediction 중 가장 보편적인 값을 찾습니다.\n",
        "print(labels)\n",
        "labels = np.squeeze(labels)   # 쓸모없는 차원을 제거합니다.\n",
        "print(labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9 2 1 ... 8 1 5]\n",
            " [9 2 1 ... 8 1 5]]\n",
            "[[9 9]\n",
            " [2 2]\n",
            " [1 1]\n",
            " ...\n",
            " [8 8]\n",
            " [1 1]\n",
            " [5 5]]\n",
            "[[9]\n",
            " [2]\n",
            " [1]\n",
            " ...\n",
            " [8]\n",
            " [1]\n",
            " [5]]\n",
            "[9 2 1 ... 8 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmZhKDdzZuoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ea361fa2-9e17-4428-c701-72efae074089"
      },
      "source": [
        "print(len(labels))\n",
        "print(len(test_labels))\n",
        "print(test_labels)\n",
        "test_label = np.argmax(test_labels, axis=1)\n",
        "print(test_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n",
            "[[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[9 2 1 ... 8 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeOKH5nJZv_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "93b3485b-db60-4f6a-b447-24deed6abbed"
      },
      "source": [
        "cnt = 0\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == test_label[i]:\n",
        "    cnt += 1\n",
        "acc = cnt / len(labels)\n",
        "print(\"Accuracy : %.4f\" % acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.9359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iruzRnyoetaR",
        "colab_type": "text"
      },
      "source": [
        "위의 코드에서 보시다시피, 변경하였을 때 유의미한 차이를 낼 수 있다고 판단한 파라미터들을 조금씩 변경해가며 최적의 accuracy가 나올 수 있도록 하였습니다."
      ]
    }
  ]
}