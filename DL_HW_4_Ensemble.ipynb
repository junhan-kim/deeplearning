{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL HW#4-Ensemble",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvItR_d35uEc",
        "colab_type": "code",
        "outputId": "26463a85-0a1e-4fca-f7aa-d95988e55d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Activation, Dropout\n",
        "from multiprocessing import Process\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyXCtsf96Ggj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "364fcb8e-4d8d-40cc-9f32-70dbd3685c11"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TONKMuhGFYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1] * train_images.shape[2]).astype('float32') / 255\n",
        "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1] * test_images.shape[2]).astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGOVxuoxA4xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = np_utils.to_categorical(train_labels, 10)\n",
        "test_labels = np_utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae4Rx5LMW2jr",
        "colab_type": "code",
        "outputId": "7721350a-0f6c-446f-b726-152086d7dfac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(128, input_dim=784, activation='relu'))\n",
        "model1.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 05:52:24.708668 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 05:52:24.745584 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 05:52:24.752850 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGWomUbnXkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "552d0eb5-3c59-4559-9877-458520ac542b"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(128, input_dim=784))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(10))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('softmax'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 05:52:24.881114 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFb5LXjnnYWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "bfcdc3e6-ef84-4a31-969d-d6aff8f9a2c4"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Dense(128, input_dim=784))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Dense(10))\n",
        "model3.add(Activation('softmax'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 05:52:25.013097 139968611243904 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuM00nxdSSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []\n",
        "models.append(model1)\n",
        "models.append(model2)\n",
        "models.append(model3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVIC_WCgoWJs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3f15219b-6451-4cd2-9725-ed6cef5a3436"
      },
      "source": [
        "for n_model in models:\n",
        "  n_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 05:52:25.052902 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 05:52:25.080041 139968611243904 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuojMEYR1Vlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c60812e4-4af8-4ebf-b0e3-bad63e84f6d6"
      },
      "source": [
        "for n_model in models:\n",
        "  n_model.fit(train_images, train_labels, epochs = 50, batch_size = 512)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 05:52:25.387039 139968611243904 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.7147 - acc: 0.7584\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.4628 - acc: 0.8416\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.4152 - acc: 0.8574\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.3871 - acc: 0.8657\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.3716 - acc: 0.8699\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3511 - acc: 0.8761\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.3379 - acc: 0.8796\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.3257 - acc: 0.8836\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.3166 - acc: 0.8868\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.3081 - acc: 0.8889\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.3015 - acc: 0.8919\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2962 - acc: 0.8932\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2863 - acc: 0.8961\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2787 - acc: 0.8995\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2788 - acc: 0.8995\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2701 - acc: 0.9026\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2646 - acc: 0.9046\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2574 - acc: 0.9087\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2548 - acc: 0.9073\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2508 - acc: 0.9099\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2444 - acc: 0.9114\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2402 - acc: 0.9130\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2404 - acc: 0.9129\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2321 - acc: 0.9149\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2317 - acc: 0.9170\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2264 - acc: 0.9183\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2221 - acc: 0.9197\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2197 - acc: 0.9209\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2177 - acc: 0.9220\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2138 - acc: 0.9231\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2129 - acc: 0.9233\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2064 - acc: 0.9253\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2074 - acc: 0.9257\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.1993 - acc: 0.9287\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1984 - acc: 0.9286\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1975 - acc: 0.9291\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1962 - acc: 0.9296\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1938 - acc: 0.9310\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1893 - acc: 0.9311\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1848 - acc: 0.9340\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1813 - acc: 0.9354\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.1807 - acc: 0.9354\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1786 - acc: 0.9363\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.1764 - acc: 0.9374\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1758 - acc: 0.9371\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1697 - acc: 0.9392\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1701 - acc: 0.9389\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1666 - acc: 0.9402\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1638 - acc: 0.9421\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1686 - acc: 0.9387\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.8239 - acc: 0.7911\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.5851 - acc: 0.8614\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.5056 - acc: 0.8757\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.4487 - acc: 0.8859\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.4079 - acc: 0.8940\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.3748 - acc: 0.8994\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.3479 - acc: 0.9050\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.3242 - acc: 0.9103\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.3050 - acc: 0.9132\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2866 - acc: 0.9181\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2710 - acc: 0.9220\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2582 - acc: 0.9250\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2455 - acc: 0.9278\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2329 - acc: 0.9308\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2204 - acc: 0.9347\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2103 - acc: 0.9374\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.2035 - acc: 0.9391\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1934 - acc: 0.9423\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1855 - acc: 0.9444\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.1777 - acc: 0.9471\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1691 - acc: 0.9503\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1659 - acc: 0.9507\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1573 - acc: 0.9532\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1529 - acc: 0.9544\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1454 - acc: 0.9571\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1413 - acc: 0.9582\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1362 - acc: 0.9602\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1282 - acc: 0.9626\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1237 - acc: 0.9645\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1224 - acc: 0.9637\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1192 - acc: 0.9650\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1147 - acc: 0.9658\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1105 - acc: 0.9683\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.1086 - acc: 0.9679\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.1015 - acc: 0.9706\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0994 - acc: 0.9704\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0924 - acc: 0.9740\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0920 - acc: 0.9738\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0947 - acc: 0.9720\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0869 - acc: 0.9755\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0859 - acc: 0.9749\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0857 - acc: 0.9747\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.0815 - acc: 0.9764\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0778 - acc: 0.9778\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0755 - acc: 0.9784\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0760 - acc: 0.9779\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0731 - acc: 0.9792\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0687 - acc: 0.9802\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0671 - acc: 0.9814\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 14us/step - loss: 0.0671 - acc: 0.9811\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 1s 13us/step - loss: 0.8238 - acc: 0.7165\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5093 - acc: 0.8264\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4491 - acc: 0.8442\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.4128 - acc: 0.8552\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3919 - acc: 0.8619\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3699 - acc: 0.8691\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3569 - acc: 0.8726\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.3444 - acc: 0.8774\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3336 - acc: 0.8805\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3241 - acc: 0.8834\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3160 - acc: 0.8862\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3118 - acc: 0.8877\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.3032 - acc: 0.8892\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2977 - acc: 0.8918\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2928 - acc: 0.8942\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2849 - acc: 0.8974\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2832 - acc: 0.8968\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2774 - acc: 0.8997\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2732 - acc: 0.9006\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2696 - acc: 0.9008\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2667 - acc: 0.9021\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2614 - acc: 0.9042\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2569 - acc: 0.9058\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.2523 - acc: 0.9088\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2487 - acc: 0.9095\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 0s 8us/step - loss: 0.2481 - acc: 0.9082\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2455 - acc: 0.9103\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2399 - acc: 0.9116\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2382 - acc: 0.9135\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2324 - acc: 0.9151\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2331 - acc: 0.9145\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2298 - acc: 0.9154\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2275 - acc: 0.9154\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2244 - acc: 0.9178\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2239 - acc: 0.9170\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2194 - acc: 0.9189\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2185 - acc: 0.9201\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2145 - acc: 0.9214\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2143 - acc: 0.9209\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2094 - acc: 0.9236\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2113 - acc: 0.9210\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2062 - acc: 0.9244\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2069 - acc: 0.9225\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2011 - acc: 0.9246\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.2030 - acc: 0.9243\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1970 - acc: 0.9272\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1963 - acc: 0.9273\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1974 - acc: 0.9274\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 1s 8us/step - loss: 0.1908 - acc: 0.9295\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.1911 - acc: 0.9298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kgya2IU8aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainModel(model, X, Y, _epochs, _batch_size):\n",
        "  model.fit(X, Y, epochs=_epochs, batch_size=_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiwB8TXvRqPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c9d78291-9d8f-43ac-face-da77ebff1a47"
      },
      "source": [
        "# 케라스는 스레드 세이프가 아니라고 하여서, 한개씩 fit 하였습니다.\n",
        "# 멀티프로세싱으로 돌렸을 때는 0.11 정도의 accuracy가 나왔습니다.  아마 tensorflow로만 구현하면 더 빠른 fit을 위해 멀티프로세싱을 활용할 수 있을 것 같습니다.\n",
        "'''\n",
        "processes = []\n",
        "for n_model in models:   # 모델들의 학습을 각각의 쓰레드에서 수행합니다.\n",
        "  p = Process(target = TrainModel, args = (n_model, train_images, train_labels, 50, 512))\n",
        "  p.start()\n",
        "  processes.append(p)\n",
        "for p in processes:        # join을 통하여 모든 프로세스가 작업을 끝낼때까지 대기합니다.\n",
        "  p.join()\n",
        "'''"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprocesses = []\\nfor n_model in models:   # 모델들의 학습을 각각의 쓰레드에서 수행합니다.\\n  p = Process(target = TrainModel, args = (n_model, train_images, train_labels, 50, 512))\\n  p.start()\\n  processes.append(p)\\nfor p in processes:        # join을 통하여 모든 프로세스가 작업을 끝낼때까지 대기합니다.\\n  p.join()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQwZgzr6yRLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "71f4aebf-8f39-4b00-881a-1444c5499136"
      },
      "source": [
        "for n_model in models:\n",
        "  print(\"Accuracy : %.4f\" % n_model.evaluate(test_images, test_labels)[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 45us/step\n",
            "Accuracy : 0.8925\n",
            "10000/10000 [==============================] - 1s 60us/step\n",
            "Accuracy : 0.8718\n",
            "10000/10000 [==============================] - 0s 47us/step\n",
            "Accuracy : 0.8922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNtPRxpjhsFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c602c63-94bc-4f66-d78a-9ab8fa06b096"
      },
      "source": [
        "labels = []\n",
        "for n_model in models:\n",
        "    predicts = np.argmax(n_model.predict(test_images), axis=1)\n",
        "    labels.append(predicts)   # 각 model에서의 predicted label을 label에 넣습니다.\n",
        "print(labels)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([9, 2, 1, ..., 8, 1, 5]), array([9, 2, 1, ..., 8, 1, 5]), array([9, 2, 1, ..., 8, 1, 5])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZz8gL31rKTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "3cdabca4-5dbb-4c6a-c8c1-ed907d2d8601"
      },
      "source": [
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "labels = np.array(labels)   \n",
        "print(labels)\n",
        "labels = np.transpose(labels, (1, 0))  # 각 column은 모델들이 특정 이미지에 대해 voting한 값들의 모임이 됩니다.\n",
        "print(labels)\n",
        "labels = scipy.stats.mode(labels, axis=1)[0]   # scipy.stats.mode => 세 모델이 내놓은 prediction 중 가장 보편적인 값을 찾습니다.\n",
        "print(labels)\n",
        "labels = np.squeeze(labels)   # 쓸모없는 차원을 제거합니다.\n",
        "print(labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9 2 1 ... 8 1 5]\n",
            " [9 2 1 ... 8 1 5]\n",
            " [9 2 1 ... 8 1 5]]\n",
            "[[9 9 9]\n",
            " [2 2 2]\n",
            " [1 1 1]\n",
            " ...\n",
            " [8 8 8]\n",
            " [1 1 1]\n",
            " [5 5 5]]\n",
            "[[9]\n",
            " [2]\n",
            " [1]\n",
            " ...\n",
            " [8]\n",
            " [1]\n",
            " [5]]\n",
            "[9 2 1 ... 8 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCiQMRh0uG2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "8675218c-da42-4713-a21c-66d3a0c8f439"
      },
      "source": [
        "print(len(labels))\n",
        "print(len(test_labels))\n",
        "print(test_labels)\n",
        "test_label = np.argmax(test_labels, axis=1)\n",
        "print(test_label)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n",
            "[[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[9 2 1 ... 8 1 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXNnXo-ZtbWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52cb2baa-7d04-4c64-f428-68d296e85cba"
      },
      "source": [
        "cnt = 0\n",
        "for i in range(len(labels)):\n",
        "  if labels[i] == test_label[i]:\n",
        "    cnt += 1\n",
        "acc = cnt / len(labels)\n",
        "print(\"Accuracy : %.4f\" % acc)\n",
        "# epoch가 작아서 그런지 미미하긴하지만, 세 모델들의 각 accuracy보다 큰 값이 나왔습니다."
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy : 0.8973\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}